---
title: "Project 3. Viterbi algorithm"
date: March 10, 2024
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r}
suppressPackageStartupMessages(library(dplyr))
set.seed(42)
```
```{r}
DSSP <- c("B", "C", "E", "G", "H", "I", "S", "T")
AA <- c("A", "C", "D", "E", "F", "G", "H", "I", "K", 
    "L", "M", "N", "P", "Q", "R", "S", "T", "U", 
    "V", "W", "X", "Y"
)
data_folder <- "../data/"
```

```{r}
#' @param E n times m matrix with the emission log probabilities of the n latent variables and m observed variables
#' @param Tr n times n matrix with the transition log probabilities
#' @param I numeric vector of length n with the initial log probabilities of the n latent variables
#' @param p a data.frame with a Variable named AminoAcids which holds the amino acid sequence as a character string
viterbi <- function(E, Tr, I, p) {
    .as.array <- function(.) stringr::str_split(., "")[[1]]
    unique.ss <- c("B", "C", "E", "G", "H", "I", "S", "T")
    unique.aa <- c("A", "C", "D", "E", "F", "G", "H", "I",
                   "K", "L", "M", "N", "P", "Q", "R", "S",
                   "T", "U", "V", "W", "X", "Y")
    for (k in seq(nrow(p))) {
        sequence <- p$AminoAcids[k]
        aa.vec <- .as.array(sequence) %>% match(unique.aa)
        P      <- matrix(0, nrow(E), length(aa.vec))
        Ptr    <- matrix(0, nrow(E), length(aa.vec))
        
        ## sets the paths
        for (i in seq(length(aa.vec))) {
            if (i == 1) {
                P[, i] <- I + E[, aa.vec[i]]
            } else {
                for (j in seq(nrow(E))) {
                    p.loc    <- P[, i - 1] + Tr[, j] + E[j, aa.vec[i]]
                    P[j, i] <- max(p.loc)
                    Ptr[j, i] <- which.max(p.loc)
                }
            }
        }
        
        ## backtrace: computes the most likely path
        Phi <- vector(mode="integer",   length=length(aa.vec))
        Phi[length(Phi)] <- which.max(P[, ncol(P)])
        ## we start at the back, just as with Needleman-Wunsch or Smith-Waterman
        for (i in seq(from=length(aa.vec), to=2)) {
            Phi[i - 1] <- Ptr[Phi[i], i]
        }
        
        states <- unique.ss[Phi]
        p$PredictedStructure[k] <- paste(states, collapse="")
    }
    return(p)
}

loading_data <- function(data_file, sec_struct) {
    col_names <- c('SeqID', 'AminoAcids')
    if(sec_struct) { col_names <- append(col_names, 'SecondaryStructure')}
    data_df <- read.csv(data_file, header=FALSE, sep="\t")
    names(data_df) <- col_names
    return(data_df)
}

assign_row_names <- function(M) {
    row.names(M) <- DSSP
    return(M)
}

assign_col_names <- function(M, aa=TRUE) {
    if (aa) {
        colnames(M) <- AA
    } else {
        colnames(M) <- DSSP
    }
    
    return(M)
}

init_matrices <- function(data) {
    # Initialisation of I, T, and E matrices using maximum likelihood

    # I - 8 x 1 matrix - initial state probabilities
    I <- matrix(0, nrow=length(DSSP), ncol=1)
    # T - 8 x 8 matrix - transition probabilities
    T <- matrix(0, nrow=length(DSSP), ncol=length(DSSP))
    # E - 8 x 22 matrix - emission probabilities
    E <- matrix(0, nrow=length(DSSP), ncol=length(AA))

    I <- assign_row_names(I)
    T <- assign_row_names(T)
    E <- assign_row_names(E)

    T <- assign_col_names(T, aa=FALSE)
    E <- assign_col_names(E)

    I <- initial_states(data, I)
    T <- transition_states(data, T)
    E <- emission_states(data, E)

    # TODO: understand, why we need to take log of matrices?
    I <- log(I)
    T <- log(T)
    E <- log(E)

    return(list(I=I, T=T, E=E))
}

initial_states <- function(data, M) {
    # Retrieving DSSP profiles
    sec_struct <- data$SecondaryStructure
    
    # Computing frequencies of each letter in the first position
    frequency <- table(substr(sec_struct, 1, 1))

    # Computing relative frequencies
    M[row.names(M) %in% names(frequency), 1] <- as.numeric(frequency)/sum(frequency)

    # Return initial states matrix
    return(M)
}

transition_states <- function(data, M) {
    # Retrieving DSSP profiles
    sec_struct <- data$SecondaryStructure
    
    pairs <- lapply(sec_struct, 
        function(x) substring(x, first=1:(nchar(x)-1), last=2:nchar(x))
    )
    frequencies <- table(unlist(pairs))

    # Assigning frequencies
    for (i in seq(nrow(M))) {
        for (j in seq(ncol(M))) {
            row_name <- row.names(M)[i]
            col_name <- colnames(M)[j]
            freq_name <- paste0(row_name, col_name)
            if (is.na(frequencies[freq_name])) {
                M[i, j] <- 1
            } else {
                M[i, j] <- as.numeric(frequencies[freq_name])+1
            }
        }
    }
    # Relative frequencies
    M <- M/rowSums(M)

    # Return transition states matrix
    return(M)
}

emission_states <- function(data, M) {
    # Retrieving profiles
    aa <- data$AminoAcids
    dssp <- data$SecondaryStructure

    aa_list <- lapply(aa,
        function(x) substring(x, first=1:(nchar(x)), last=1:nchar(x))
    )
    dssp_list <- lapply(dssp, 
        function(x) substring(x, first=1:(nchar(x)), last=1:nchar(x))
    )
    
    frequencies <- table(paste(unlist(dssp_list), unlist(aa_list), sep=""))

    # Assigning frequencies
    for (i in seq(nrow(M))) {
        for (j in seq(ncol(M))) {
            row_name <- row.names(M)[i]
            col_name <- colnames(M)[j]
            freq_name <- paste0(row_name, col_name)
            if (is.na(frequencies[freq_name])) {
                M[i, j] <- 1
            } else {
                M[i, j] <- as.numeric(frequencies[freq_name])+1
            }
        }
    }
    # Relative frequencies
    M <- M/rowSums(M)

    # Return initial states matrix
    return(M)
}

eigen_stationary_distribution <- function(T) {
    # T transposed to get left eigenvectors of T
    e <- eigen(t(exp(T)))
    e_vec <- e$vectors
    e_val <- e$values
    e_val_one_index <- which(abs(e_val-1) < 1e-12)
    stat_dist <- matrix(e_vec[, e_val_one_index]/
        sum(e_vec[, e_val_one_index]), nrow=1, ncol=length(DSSP)
    )
    colnames(stat_dist) <- DSSP
    print("Stationary distribution of transmission probabilities (eigenvalue approach): ")
    print(stat_dist)
    return(stat_dist)
}

brute_force_stationary_distribution <- function(T) {
    T <- exp(T)
    while (sum(abs(T[1,]-T[2,])) > 1e-12) {
        T <- T %*% T
    }
    print("Stationary distribution of transmission probabilities (brute-force approach): ")
    print(T[1,])
}

run_viterbi_predictions <- function(data, params) {
    pred_df <- data.frame(AminoAcids=data$AminoAcids, PredictedStructure=NA)
    pred_df <- apply(pred_df, 1, function(row) {
        viterbi(params$E, params$T, params$I, data.frame(AminoAcids=row["AminoAcids"]))
    })
    pred_df <- data.frame(t(sapply(pred_df, function(x) x[1:max(lengths(pred_df))])))
    data$PredictedStructure <- pred_df$PredictedStructure
    data <- apply(data, 2, as.character)
    return(data)
}

run_random_predictions <- function(data, params) {
    rand_struct <- apply(data, 1, function(row) {
        paste0(sample(DSSP, nchar(row["AminoAcids"]), replace=TRUE), collapse="")
    })
    data <- cbind(data, RandomStructure=rand_struct)
    return(data)
}

save_to_tsv <- function(data, file_path) {
    write.table(data, file=file_path, sep="\t", row.names=FALSE, col.names=FALSE)
}

get_accuracies <- function(pred_df, column_name) {
    accuracies <- apply(pred_df, 1, function(row) {
        sum(
            strsplit(row["SecondaryStructure"], "")[[1]] == strsplit(row[column_name], "")[[1]])/
            nchar(row["SecondaryStructure"])
    })
    print(summary(accuracies))
    return(accuracies)
}

get_bootstrapped_data <- function(data) {
    bootstrapped_data <- slice_sample(data, n=nrow(data), replace=TRUE)
    return(bootstrapped_data)
}

process_bootstrap_params <- function(boot_params, params, n_boot) {
    boot_params <- array(unlist(boot_params), dim=c(dim(params), n_boot))
    dimnames(boot_params) <- list(rownames(params), colnames(params), NULL)
    return(boot_params)
}

compute_CI <- function(boot_params) {
    n_values <- dim(boot_params)[1] * dim(boot_params)[2]
    lower_CI <- matrix(NA, nrow=dim(boot_params)[1], ncol=dim(boot_params)[2])
    upper_CI <- matrix(NA, nrow=dim(boot_params)[1], ncol=dim(boot_params)[2])

    mapply(function(i) {
        mapply(function(i, j) {
            values <- boot_params[i, j, ]
            lower <- quantile(values, 0.025)
            upper <- quantile(values, 0.975)
            lower_CI[i, j] <<- lower
            upper_CI[i, j] <<- upper
        }, i, 1:dim(boot_params)[2])
    }, 1:dim(boot_params)[1])

    # Collecting CIs of parameters in the diagonal
    CI <- matrix(NA, nrow=dim(lower_CI)[1], ncol=2)
    if(dim(lower_CI)[2] == 1) {
        CI[, 1] <- lower_CI
        CI[, 2] <- upper_CI
    } else {
        mapply(function(i) {
                CI[i, 1] <<- lower_CI[i, i]
                CI[i, 2] <<- upper_CI[i, i]
            }, 1:dim(lower_CI)[1]
        )
    }

    # Returning diagonal parameters' CIs
    # and separately lower and upper bounds for CIs 
    # of all parameters in the matrix
    return(list(diag_param_CI=CI, lower_CI=lower_CI, upper_CI=upper_CI))
}

```
```{r}
# Loading data
prot_train_df <- loading_data(paste0(data_folder, "proteins_train.tsv"), sec_struct=TRUE)
prot_test_df <- loading_data(paste0(data_folder, "proteins_test.tsv"), sec_struct=TRUE)
prot_new_df <- loading_data(paste0(data_folder, "proteins_new.tsv"), sec_struct=FALSE)
```
```{r}
# Initialisation of parameters
params <- init_matrices(prot_train_df)
```

```{r}
# Stationary distribution
eigen_stationary_distribution(params$T)
brute_force_stationary_distribution(params$T)
```

```{r}
# Making predictions
prot_test_df <- run_viterbi_predictions(prot_test_df, params)
prot_new_df <- run_viterbi_predictions(prot_new_df, params)

# Saving predictions
save_to_tsv(prot_new_df, paste0(data_folder, "proteins_new_pred.tsv"))

# Computing prediction accuracies
print("Accuracy statistics of Viterbi predictions:")
viterbi_acc <- get_accuracies(prot_test_df, column_name="PredictedStructure")

# Making random "predictions"
prot_test_df <- run_random_predictions(prot_test_df, params)
print("Accuracy statistics of random 'predictions':")
rand_acc <- get_accuracies(prot_test_df, column_name="RandomStructure")

# Plot box plot from accuracies
boxplot(rand_acc, viterbi_acc, ylim=c(0, 1), ylab="Accuracy", xlab="Algorithm",
    names=c("Random", "Viterbi")
)
```
```{r}
# Bootstrapping for parameter CFs
# TODO: change the number of bootstraps
N_BOOT <- 1000
boot_params <- list(I=list(), T=list(), E=list())

for (i in 1:N_BOOT) {
    boot_data <- get_bootstrapped_data(prot_train_df)
    params <- init_matrices(boot_data)

    boot_params$I <- list(boot_params$I, params$I)
    boot_params$T <- list(boot_params$T, params$T)
    boot_params$E <- list(boot_params$E, params$E)
}

boot_params$I <- process_bootstrap_params(boot_params$I, params$I, N_BOOT)
boot_params$T <- process_bootstrap_params(boot_params$T, params$T, N_BOOT)
boot_params$E <- process_bootstrap_params(boot_params$E, params$E, N_BOOT)

# Computing confidence intervals for parameter matrices
CI_I <- compute_CI(exp(boot_params$I))
CI_T <- compute_CI(exp(boot_params$T))
CI_E <- compute_CI(exp(boot_params$E))
print(CI_I)
print(CI_T)
print(CI_E)
```

## Render this .rmd into a pdf

```{r, eval=FALSE}
library(rmarkdown)
render("viterbi.Rmd", pdf_document(TRUE), "viterbi.pdf")
```
