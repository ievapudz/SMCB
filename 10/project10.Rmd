---
title: "Project 10"
output:
  pdf_document: 
    extra_dependencies: ['amsmath']
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

# Problem 29

```{r}
library(caret)
library(glmnet)
library(pROC)
```

## Loading data

```{r}
load(file='yeastStorey.rda')
```

```{r}
print(nrow(data))
print(ncol(data))
```

```{r}
head(data)
```

## Shuffling data (splitting into training and validation)

```{r}
set.seed(42)
trainIndex <- createDataPartition(data$Marker, p=0.7, list=FALSE, times=1)
trainData <- data[trainIndex,]
testData <- data[-trainIndex,]
```

```{r}
trainData
```

```{r}
testData
```

## Cross-validation of elastic-net model

```{r}
x <- trainData[, !(names(trainData) %in% c("Marker"))]
x <- as.matrix(x)
y <- trainData$Marker
```

```{r}
foldid <- sample(1:10, size=length(y), replace=TRUE)
alphas <- seq(0, 1, by=0.1)

elasticNetCVAlpha <- function(alpha) {
  cv.glmnet(x, y, family="binomial", alpha=alpha, nfolds=10, foldid=foldid)
}

resultsCV <- lapply(alphas, elasticNetCVAlpha)
```

```{r}
for(i in 1:11) { print(paste0("alpha=", alphas[i], "; error=", mean(resultsCV[[i]]$cvm))) }
```
$\alpha$ with which mean of mean cross-validated error is the smallest: $\alpha=1$.
This alpha will be considered as optimal.

### Plotting mean cross-validated error

Cross-validated error function is binomial deviance.

```{r}
plot(resultsCV[[11]], ylab="cross-validated error")
```

### Plotting trace curve of coefficients

```{r}
plot(resultsCV[[11]]$glmnet.fit, "lambda")
```

```{r, eval=FALSE}
library(rmarkdown)
render("Gibbs.Rmd", pdf_document(TRUE), "Indilewitsch_Toidze_Houhamdi_Pudziuvelyte_Project6.pdf")
```
